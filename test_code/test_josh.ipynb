{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "# import tensorflow as tf\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input\n",
    "\n",
    "# from utils.util import load_model\n",
    "# from network.network_utils import build_model\n",
    "# from network.optimizer_utils import get_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Network as models\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {0:'Male', 1:'Female'}\n",
    "race_dict = {0:'White', 1:'Black', 2:'Asian', 3:'Indian', 4:'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(cfg):\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.gpu\n",
    "\n",
    "#     net = build_model(cfg)\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.backends.cudnn.benchmark = True\n",
    "#         net = net.cuda()\n",
    "\n",
    "#     optimizer = get_optimizer(cfg, net)\n",
    "#     lr_scheduler = get_scheduler(cfg, optimizer)\n",
    "\n",
    "#     if cfg.dataset_name == 'morph':\n",
    "#         test_ref_dataset = morph.MorphRef(cfg=cfg, tau=cfg.tau, dataset_dir=cfg.dataset_root)\n",
    "#         test_dataset = morph.MorphTest(cfg=cfg, dataset_dir=cfg.dataset_root)\n",
    "\n",
    "#         test_ref_loader = DataLoader(test_ref_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=False, pin_memory=True)\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, num_workers=cfg.num_workers, shuffle=False, pin_memory=True)\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(f'Undefined database ({cfg.dataset_name}) has been given')\n",
    "\n",
    "#     if cfg.load:\n",
    "#         load_model(cfg, net, optimizer=optimizer, load_optim_params=False)\n",
    "\n",
    "#     if lr_scheduler:\n",
    "#        lr_scheduler.step()\n",
    "\n",
    "#     net.eval()\n",
    "#     test(cfg, net, test_ref_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Sequential):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.convA = nn.Conv2d(input_channel, output_channel, kernel_size=1, stride=1)\n",
    "        self.leakyreluA = nn.ReLU()\n",
    "        self.convB = nn.Conv2d(output_channel, output_channel, kernel_size=1, stride=1)\n",
    "        self.leakyreluB = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.convC = nn.Conv2d(output_channel, 1, kernel_size=1, stride=1)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convA(x)\n",
    "        x = self.leakyreluA(x)\n",
    "        x = self.convB(x)\n",
    "        x = self.leakyreluB(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.convC(x)\n",
    "\n",
    "        return self.activation(x)\n",
    "\n",
    "class Global_Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Global_Regressor, self).__init__()\n",
    "        self.encoder = ptcv_get_model(\"bn_vgg16\", pretrained=True)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=7)\n",
    "        self.regressor = Regressor(1536, 512)\n",
    "\n",
    "    def forward_siamese(self, x):\n",
    "        x = self.encoder.features.stage1(x)\n",
    "        x = self.encoder.features.stage2(x)\n",
    "        x = self.encoder.features.stage3(x)\n",
    "        x = self.encoder.features.stage4(x)\n",
    "        x = self.encoder.features.stage5(x)\n",
    "        x = self.avg_pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, phase, **kwargs):\n",
    "\n",
    "        # if phase == 'train':\n",
    "        #     x_1_1, x_1_2, x_2 = kwargs['x_1_1'], kwargs['x_1_2'], kwargs['x_2']\n",
    "        #     x_1_1 = self.forward_siamese(x_1_1)\n",
    "        #     x_1_2 = self.forward_siamese(x_1_2)\n",
    "        #     x_2 = self.forward_siamese(x_2)\n",
    "\n",
    "        #     x = torch.cat([x_1_1, x_1_2, x_2], dim=1)\n",
    "\n",
    "        #     output = self.regressor(x)\n",
    "\n",
    "        #     return output\n",
    "\n",
    "        if phase == 'test':\n",
    "            x_1_1, x_1_2, x_2 = kwargs['x_1_1'], kwargs['x_1_2'], kwargs['x_2']\n",
    "            x = torch.cat([x_1_1, x_1_2, x_2], dim=1)\n",
    "\n",
    "            output = self.regressor(x)\n",
    "\n",
    "            return output\n",
    "\n",
    "        # elif phase == 'extraction':\n",
    "        #     x = kwargs['x']\n",
    "        #     x = self.forward_siamese(x)\n",
    "\n",
    "        #     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['encoder.features.stage1.unit1.conv.weight', 'encoder.features.stage1.unit1.bn.weight', 'encoder.features.stage1.unit1.bn.bias', 'encoder.features.stage1.unit1.bn.running_mean', 'encoder.features.stage1.unit1.bn.running_var', 'encoder.features.stage1.unit1.bn.num_batches_tracked', 'encoder.features.stage1.unit2.conv.weight', 'encoder.features.stage1.unit2.bn.weight', 'encoder.features.stage1.unit2.bn.bias', 'encoder.features.stage1.unit2.bn.running_mean', 'encoder.features.stage1.unit2.bn.running_var', 'encoder.features.stage1.unit2.bn.num_batches_tracked', 'encoder.features.stage2.unit1.conv.weight', 'encoder.features.stage2.unit1.bn.weight', 'encoder.features.stage2.unit1.bn.bias', 'encoder.features.stage2.unit1.bn.running_mean', 'encoder.features.stage2.unit1.bn.running_var', 'encoder.features.stage2.unit1.bn.num_batches_tracked', 'encoder.features.stage2.unit2.conv.weight', 'encoder.features.stage2.unit2.bn.weight', 'encoder.features.stage2.unit2.bn.bias', 'encoder.features.stage2.unit2.bn.running_mean', 'encoder.features.stage2.unit2.bn.running_var', 'encoder.features.stage2.unit2.bn.num_batches_tracked', 'encoder.features.stage3.unit1.conv.weight', 'encoder.features.stage3.unit1.bn.weight', 'encoder.features.stage3.unit1.bn.bias', 'encoder.features.stage3.unit1.bn.running_mean', 'encoder.features.stage3.unit1.bn.running_var', 'encoder.features.stage3.unit1.bn.num_batches_tracked', 'encoder.features.stage3.unit2.conv.weight', 'encoder.features.stage3.unit2.bn.weight', 'encoder.features.stage3.unit2.bn.bias', 'encoder.features.stage3.unit2.bn.running_mean', 'encoder.features.stage3.unit2.bn.running_var', 'encoder.features.stage3.unit2.bn.num_batches_tracked', 'encoder.features.stage3.unit3.conv.weight', 'encoder.features.stage3.unit3.bn.weight', 'encoder.features.stage3.unit3.bn.bias', 'encoder.features.stage3.unit3.bn.running_mean', 'encoder.features.stage3.unit3.bn.running_var', 'encoder.features.stage3.unit3.bn.num_batches_tracked', 'encoder.features.stage4.unit1.conv.weight', 'encoder.features.stage4.unit1.bn.weight', 'encoder.features.stage4.unit1.bn.bias', 'encoder.features.stage4.unit1.bn.running_mean', 'encoder.features.stage4.unit1.bn.running_var', 'encoder.features.stage4.unit1.bn.num_batches_tracked', 'encoder.features.stage4.unit2.conv.weight', 'encoder.features.stage4.unit2.bn.weight', 'encoder.features.stage4.unit2.bn.bias', 'encoder.features.stage4.unit2.bn.running_mean', 'encoder.features.stage4.unit2.bn.running_var', 'encoder.features.stage4.unit2.bn.num_batches_tracked', 'encoder.features.stage4.unit3.conv.weight', 'encoder.features.stage4.unit3.bn.weight', 'encoder.features.stage4.unit3.bn.bias', 'encoder.features.stage4.unit3.bn.running_mean', 'encoder.features.stage4.unit3.bn.running_var', 'encoder.features.stage4.unit3.bn.num_batches_tracked', 'encoder.features.stage5.unit1.conv.weight', 'encoder.features.stage5.unit1.bn.weight', 'encoder.features.stage5.unit1.bn.bias', 'encoder.features.stage5.unit1.bn.running_mean', 'encoder.features.stage5.unit1.bn.running_var', 'encoder.features.stage5.unit1.bn.num_batches_tracked', 'encoder.features.stage5.unit2.conv.weight', 'encoder.features.stage5.unit2.bn.weight', 'encoder.features.stage5.unit2.bn.bias', 'encoder.features.stage5.unit2.bn.running_mean', 'encoder.features.stage5.unit2.bn.running_var', 'encoder.features.stage5.unit2.bn.num_batches_tracked', 'encoder.features.stage5.unit3.conv.weight', 'encoder.features.stage5.unit3.bn.weight', 'encoder.features.stage5.unit3.bn.bias', 'encoder.features.stage5.unit3.bn.running_mean', 'encoder.features.stage5.unit3.bn.running_var', 'encoder.features.stage5.unit3.bn.num_batches_tracked', 'encoder.output.fc1.fc.weight', 'encoder.output.fc1.fc.bias', 'encoder.output.fc2.fc.weight', 'encoder.output.fc2.fc.bias', 'encoder.output.fc3.weight', 'encoder.output.fc3.bias', 'regressor.convA.weight', 'regressor.convA.bias', 'regressor.convB.weight', 'regressor.convB.bias', 'regressor.convC.weight', 'regressor.convC.bias'])\n",
      "=> loaded checkpoint '/Users/josh/r/cv_final_project/test_code/../hdd1/2023/2022CVPR_code_publish/results/results_mwr/utk/MWR/Back_vgg16bn_M_MWR_T0.20_2024-05-09 00:38:15/mae_Epoch_4_MAE_5.9005_CS_0.5543.pth'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Global_Regressor(\n",
       "  (encoder): VGG(\n",
       "    (features): Sequential(\n",
       "      (stage1): Sequential(\n",
       "        (unit1): ConvBlock(\n",
       "          (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit2): ConvBlock(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (stage2): Sequential(\n",
       "        (unit1): ConvBlock(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit2): ConvBlock(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (stage3): Sequential(\n",
       "        (unit1): ConvBlock(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit2): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit3): ConvBlock(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (stage4): Sequential(\n",
       "        (unit1): ConvBlock(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit2): ConvBlock(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit3): ConvBlock(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (stage5): Sequential(\n",
       "        (unit1): ConvBlock(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit2): ConvBlock(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (unit3): ConvBlock(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (output): VGGOutputBlock(\n",
       "      (fc1): VGGDense(\n",
       "        (fc): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "        (activ): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc2): VGGDense(\n",
       "        (fc): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (activ): ReLU(inplace=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "  (regressor): Regressor(\n",
       "    (convA): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (leakyreluA): ReLU()\n",
       "    (convB): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (leakyreluB): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (convC): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:%s\" % (arg.gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "model = Global_Regressor()\n",
    "\n",
    "model_path = 'Back_vgg16bn_M_MWR_T0.20_2024-05-09 00:38:15/mae_Epoch_4_MAE_5.9005_CS_0.5543.pth'\n",
    "initial_model = os.path.join(os.getcwd(), '../hdd1/2023/2022CVPR_code_publish/results/results_mwr/utk/MWR', model_path)\n",
    "\n",
    "### Load network parameters ###\n",
    "checkpoint = torch.load(initial_model)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "model_dict.update(checkpoint['model_state_dict'])\n",
    "print(model_dict.keys())\n",
    "model.load_state_dict(model_dict)\n",
    "print(\"=> loaded checkpoint '{}'\".format(initial_model))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Age: 4.424435780191368\n"
     ]
    }
   ],
   "source": [
    "def get_reference_ages():\n",
    "    return 1, 116\n",
    "\n",
    "def load_and_preprocess_image(model, image_path):\n",
    "    # Define the image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to the input size expected by VGG16\n",
    "        transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet mean normalization\n",
    "                             std=[0.229, 0.224, 0.225])   # ImageNet std normalization\n",
    "    ])\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension\n",
    "    image = model.forward_siamese(image)\n",
    "    return image\n",
    "\n",
    "def predict_age(model, image_tensor):\n",
    "    # Duplicate the preprocessed image tensor to match expected input format\n",
    "    input_tensors = {'x_1_1': image_tensor, 'x_1_2': image_tensor, 'x_2': image_tensor}\n",
    "\n",
    "    # Predict using the model\n",
    "    with torch.no_grad():\n",
    "        output = model.forward('test', **input_tensors)\n",
    "        # Assuming the model outputs a single value per input batch\n",
    "        output = output.squeeze().item()\n",
    "    \n",
    "        up_age, lb_age = get_reference_ages()\n",
    "\n",
    "        # Convert these ages into the logarithmic scale for calculations\n",
    "        log_up_age = np.log(up_age)\n",
    "        log_lb_age = np.log(lb_age)\n",
    "\n",
    "        # Calculate the mean and tau (difference) in the logarithmic scale\n",
    "        mean_log_age = (log_up_age + log_lb_age) / 2\n",
    "        tau = abs(mean_log_age - log_lb_age)\n",
    "\n",
    "        # Calculate the refined age using the model's output\n",
    "        refined_log_age = output * tau + mean_log_age\n",
    "        predicted_age = np.exp(refined_log_age)\n",
    "\n",
    "    return predicted_age\n",
    "\n",
    "image_path = '/Users/josh/Downloads/UTKFace/10_1_0_20170109203642966.jpg'\n",
    "image_path = '/Users/josh/Downloads/UTKFace/90_1_0_20170110183452817.jpg'\n",
    "# Assuming you have a function to load and preprocess the image\n",
    "image_tensor = load_and_preprocess_image(model, image_path)  # Ensure this matches model input expectations\n",
    "\n",
    "# # Simulate the same input for all three branches (if your model logic allows for this)\n",
    "# input_dict = {'x_1_1': image_tensor, 'x_1_2': image_tensor, 'x_2': image_tensor}\n",
    "\n",
    "# # Predict the age\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_age = predict_age(model, image_tensor)\n",
    "    # output = model.forward('test', **input_dict)\n",
    "    # predicted_age = output.squeeze().item()  # Assuming the model output is directly interpretable as age\n",
    "\n",
    "print(f'Predicted Age: {predicted_age}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4871427630287601\n",
      "refined age: 4.424435780191368\n",
      "age: 58.5\n",
      "1.4871427630287601\n",
      "refined age: 4.424435780191368\n",
      "age: 4\n",
      "Predicted Age: 4\n"
     ]
    }
   ],
   "source": [
    "def predict_age(model, feature_test, lb_age, up_age, max_iter=10, tau=0.5, device='cpu'):\n",
    "\n",
    "    feature_test = torch.as_tensor(feature_test).to(device).reshape(-1, 512, 1, 1)\n",
    "    memory = np.zeros(max_iter, dtype=int)\n",
    "\n",
    "    # Calculate mean and tau for the output age\n",
    "    log_lb_age = np.log(lb_age)\n",
    "    log_up_age = np.log(up_age)\n",
    "    mean = (log_lb_age + log_up_age) / 2\n",
    "    tau = abs(mean - log_lb_age)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        age = (lb_age + up_age) / 2  # Starting with the middle age as initial\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            outputs = model('test', x_1_1=feature_test, x_1_2=feature_test, x_2=feature_test)\n",
    "            output = outputs.squeeze().cpu().detach().numpy()\n",
    "\n",
    "            refined_age = np.exp(output * tau + mean)\n",
    "            print('refined age:', refined_age)\n",
    "            print('age:', age)\n",
    "\n",
    "            if max_iter == iteration or int(refined_age + 0.5) == int(age):\n",
    "                age = int(refined_age + 0.5)\n",
    "                memory[iteration] = age\n",
    "                break\n",
    "            else:\n",
    "                age = int(refined_age + 0.5)\n",
    "                memory[iteration] = age\n",
    "                iteration += 1\n",
    "\n",
    "    return age\n",
    "\n",
    "# Example usage\n",
    "image_path = '/Users/josh/Downloads/UTKFace/90_1_0_20170110183452817.jpg'\n",
    "\n",
    "feature_test = load_and_preprocess_image(model, image_path)  # Load your image features prepared as expected by the model\n",
    "lb_age = 1  # Lower bound of age\n",
    "up_age = 116  # Upper bound of age\n",
    "\n",
    "predicted_age = predict_age(model, feature_test, lb_age, up_age)\n",
    "print(f\"Predicted Age: {predicted_age}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1, 1])\n",
      "torch.Size([1, 1536, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def check_output_dimensions(model, input_tensor):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    output = model.forward_siamese(input_tensor)\n",
    "    print(output.shape)  # This should print the shape of the output tensor\n",
    "\n",
    "# Prepare an example input tensor that simulates a batch of one image\n",
    "example_input = torch.randn(1, 3, 224, 224)  # Assuming the input size is 224x224 and 3 channels for RGB\n",
    "check_output_dimensions(model, example_input)\n",
    "\n",
    "# Assuming each siamese branch outputs [1, 512, H, W]\n",
    "output1 = torch.randn(1, 512, 1, 1)  # Simulate output from one branch\n",
    "output2 = torch.randn(1, 512, 1, 1)  # Simulate output from another branch\n",
    "output3 = torch.randn(1, 512, 1, 1)  # Simulate output from the third branch\n",
    "\n",
    "concatenated_output = torch.cat([output1, output2, output3], dim=1)\n",
    "print(concatenated_output.shape)  # This should print [1, 1536, 1, 1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
